{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps for all of us\n",
    "\n",
    "Choose a dataset that you want to use. \n",
    "\n",
    "You may do whatever steps you think necessary for building the best classifier.\n",
    "\n",
    "Take the data you chose and do whatever massaging you think is necessary: standardizing, scaling, feature engineering/ transforming, feature selection, etc.  \n",
    "\n",
    "Build a classifier however you see fit. You may want build one and tweak the paramters manually or use some sort of grid search to look through all possible parameters. \n",
    "\n",
    "Remember: The same model built on the massaged data may perform better than if the data was untouched. It may be more conveniant to chose a standared massaging pipeline and tweak a model to that data.\n",
    "\n",
    "After you massage your data, follow these steps:\n",
    "\n",
    "if you want to balance your target (which you should) follow along these lines:\n",
    "\n",
    "### build your features data and target data\n",
    "\n",
    "- X = df.drop(columns = \"whatever your target name is\")\n",
    "- y = df\"whatever your target name is\"\n",
    "\n",
    "### split the data into training and testing\n",
    "\n",
    "- X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2019)\n",
    "\n",
    "### create the oversampled data to train on \n",
    "\n",
    "- oversampler = SMOTE(random_state = 2019)\n",
    "- X_train_oversampled, y_train_oversampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "### Put the oversampled data back into a dataframe\n",
    "\n",
    "- X_train_oversampled = pd.DataFrame(X_train_oversampled, columns = X_train.columns)\n",
    "- y_train_oversampled = pd.Series(y_train_oversampled)\n",
    "\n",
    "### Build your classifier here. As an example:\n",
    "\n",
    "- xgb_clf = xgb.XGBClassifier(max_depth=5, n_estimators=100, colsample_bytree=0.3, learning_rate=0.1, n_jobs=-1)\n",
    "\n",
    " \n",
    "### Fit to the oversampled data; this will train the classifier on the oversampled data\n",
    "\n",
    "- xgb_clf.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "### Use 5-fold cross validation to see how well the classfier you built is doing on test data. \n",
    "Some points: you have to substitute your classifer name in the cross_val_score function \n",
    "\n",
    "- kfold = KFold(n_splits=5, random_state=2019)\n",
    "- results = cross_val_score(xgb_clf, X_test, y_test, cv=kfold, scoring = 'f1')\n",
    "\n",
    "\n",
    "## It may be best to keep all of your models you built; have a log of them to see their scores and keep a record of your process of building your data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from Modules import *\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "import imblearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in the full sequential data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_1</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_2</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_3</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_4</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_5</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_6</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEX_Female</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEX_Male</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION_Graduate School</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION_Other</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION_University</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARRIAGE_Married</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARRIAGE_Non-married</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERCENT_OF_LIMIT_BAL1</th>\n",
       "      <td>0.195650</td>\n",
       "      <td>0.022350</td>\n",
       "      <td>0.308011</td>\n",
       "      <td>0.899800</td>\n",
       "      <td>0.132340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERCENT_OF_LIMIT_BAL2</th>\n",
       "      <td>0.120650</td>\n",
       "      <td>0.006042</td>\n",
       "      <td>0.139189</td>\n",
       "      <td>0.924280</td>\n",
       "      <td>-0.620220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERCENT_OF_LIMIT_BAL3</th>\n",
       "      <td>0.034450</td>\n",
       "      <td>0.014017</td>\n",
       "      <td>0.139544</td>\n",
       "      <td>0.961820</td>\n",
       "      <td>0.516700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERCENT_OF_LIMIT_BAL4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018933</td>\n",
       "      <td>0.148122</td>\n",
       "      <td>0.544280</td>\n",
       "      <td>0.238800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERCENT_OF_LIMIT_BAL5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028792</td>\n",
       "      <td>0.154978</td>\n",
       "      <td>0.557800</td>\n",
       "      <td>0.369140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERCENT_OF_LIMIT_BAL6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010508</td>\n",
       "      <td>0.117211</td>\n",
       "      <td>0.570940</td>\n",
       "      <td>0.369040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERCENT_OF_LIMIT_BAL_1_INDICATOR</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERCENT_OF_LIMIT_BAL_2_INDICATOR</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERCENT_OF_LIMIT_BAL_3_INDICATOR</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERCENT_OF_LIMIT_BAL_4_INDICATOR</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERCENT_OF_LIMIT_BAL_5_INDICATOR</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_RATIO_1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051917</td>\n",
       "      <td>0.042562</td>\n",
       "      <td>0.232099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_RATIO_2</th>\n",
       "      <td>0.222115</td>\n",
       "      <td>0.579710</td>\n",
       "      <td>0.106937</td>\n",
       "      <td>0.041859</td>\n",
       "      <td>6.469312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_RATIO_3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.372856</td>\n",
       "      <td>0.073752</td>\n",
       "      <td>0.024345</td>\n",
       "      <td>0.279057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_RATIO_4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305623</td>\n",
       "      <td>0.069779</td>\n",
       "      <td>0.038850</td>\n",
       "      <td>0.429799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_RATIO_5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066899</td>\n",
       "      <td>0.036914</td>\n",
       "      <td>0.035987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_RATIO_6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.613309</td>\n",
       "      <td>0.321564</td>\n",
       "      <td>0.033844</td>\n",
       "      <td>0.035492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_RATIO_1_INDICATOR</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_RATIO_2_INDICATOR</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_RATIO_3_INDICATOR</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_RATIO_4_INDICATOR</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_RATIO_5_INDICATOR</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          0          1          2          3  \\\n",
       "AGE                               24.000000  26.000000  34.000000  37.000000   \n",
       "PAY_1                              2.000000  -1.000000   0.000000   0.000000   \n",
       "PAY_2                              2.000000   2.000000   0.000000   0.000000   \n",
       "PAY_3                             -1.000000   0.000000   0.000000   0.000000   \n",
       "PAY_4                             -1.000000   0.000000   0.000000   0.000000   \n",
       "PAY_5                             -2.000000   0.000000   0.000000   0.000000   \n",
       "PAY_6                             -2.000000   2.000000   0.000000   0.000000   \n",
       "Y                                  1.000000   1.000000   0.000000   0.000000   \n",
       "SEX_Female                         1.000000   1.000000   1.000000   1.000000   \n",
       "SEX_Male                           0.000000   0.000000   0.000000   0.000000   \n",
       "EDUCATION_Graduate School          0.000000   0.000000   0.000000   0.000000   \n",
       "EDUCATION_Other                    0.000000   0.000000   0.000000   0.000000   \n",
       "EDUCATION_University               1.000000   1.000000   1.000000   1.000000   \n",
       "MARRIAGE_Married                   1.000000   0.000000   0.000000   1.000000   \n",
       "MARRIAGE_Non-married               0.000000   1.000000   1.000000   0.000000   \n",
       "PERCENT_OF_LIMIT_BAL1              0.195650   0.022350   0.308011   0.899800   \n",
       "PERCENT_OF_LIMIT_BAL2              0.120650   0.006042   0.139189   0.924280   \n",
       "PERCENT_OF_LIMIT_BAL3              0.034450   0.014017   0.139544   0.961820   \n",
       "PERCENT_OF_LIMIT_BAL4              0.000000   0.018933   0.148122   0.544280   \n",
       "PERCENT_OF_LIMIT_BAL5              0.000000   0.028792   0.154978   0.557800   \n",
       "PERCENT_OF_LIMIT_BAL6              0.000000   0.010508   0.117211   0.570940   \n",
       "PERCENT_OF_LIMIT_BAL_1_INDICATOR   1.000000   1.000000   1.000000   0.000000   \n",
       "PERCENT_OF_LIMIT_BAL_2_INDICATOR   1.000000   0.000000   0.000000   0.000000   \n",
       "PERCENT_OF_LIMIT_BAL_3_INDICATOR   1.000000   0.000000   0.000000   1.000000   \n",
       "PERCENT_OF_LIMIT_BAL_4_INDICATOR   0.000000   0.000000   0.000000   0.000000   \n",
       "PERCENT_OF_LIMIT_BAL_5_INDICATOR   0.000000   1.000000   1.000000   0.000000   \n",
       "PAY_RATIO_1                        0.000000   0.000000   0.051917   0.042562   \n",
       "PAY_RATIO_2                        0.222115   0.579710   0.106937   0.041859   \n",
       "PAY_RATIO_3                        0.000000   0.372856   0.073752   0.024345   \n",
       "PAY_RATIO_4                        1.000000   0.305623   0.069779   0.038850   \n",
       "PAY_RATIO_5                        1.000000   0.000000   0.066899   0.036914   \n",
       "PAY_RATIO_6                        1.000000   0.613309   0.321564   0.033844   \n",
       "PAY_RATIO_1_INDICATOR              1.000000   1.000000   1.000000   0.000000   \n",
       "PAY_RATIO_2_INDICATOR              0.000000   0.000000   0.000000   0.000000   \n",
       "PAY_RATIO_3_INDICATOR              0.600000   0.000000   0.000000   0.600000   \n",
       "PAY_RATIO_4_INDICATOR              0.000000   0.000000   0.000000   0.000000   \n",
       "PAY_RATIO_5_INDICATOR              0.000000   0.200000   0.200000   0.000000   \n",
       "\n",
       "                                          4  \n",
       "AGE                               57.000000  \n",
       "PAY_1                             -1.000000  \n",
       "PAY_2                              0.000000  \n",
       "PAY_3                             -1.000000  \n",
       "PAY_4                              0.000000  \n",
       "PAY_5                              0.000000  \n",
       "PAY_6                              0.000000  \n",
       "Y                                  0.000000  \n",
       "SEX_Female                         0.000000  \n",
       "SEX_Male                           1.000000  \n",
       "EDUCATION_Graduate School          0.000000  \n",
       "EDUCATION_Other                    0.000000  \n",
       "EDUCATION_University               1.000000  \n",
       "MARRIAGE_Married                   1.000000  \n",
       "MARRIAGE_Non-married               0.000000  \n",
       "PERCENT_OF_LIMIT_BAL1              0.132340  \n",
       "PERCENT_OF_LIMIT_BAL2             -0.620220  \n",
       "PERCENT_OF_LIMIT_BAL3              0.516700  \n",
       "PERCENT_OF_LIMIT_BAL4              0.238800  \n",
       "PERCENT_OF_LIMIT_BAL5              0.369140  \n",
       "PERCENT_OF_LIMIT_BAL6              0.369040  \n",
       "PERCENT_OF_LIMIT_BAL_1_INDICATOR   1.000000  \n",
       "PERCENT_OF_LIMIT_BAL_2_INDICATOR   0.000000  \n",
       "PERCENT_OF_LIMIT_BAL_3_INDICATOR   1.000000  \n",
       "PERCENT_OF_LIMIT_BAL_4_INDICATOR   0.000000  \n",
       "PERCENT_OF_LIMIT_BAL_5_INDICATOR   1.000000  \n",
       "PAY_RATIO_1                        0.232099  \n",
       "PAY_RATIO_2                        6.469312  \n",
       "PAY_RATIO_3                        0.279057  \n",
       "PAY_RATIO_4                        0.429799  \n",
       "PAY_RATIO_5                        0.035987  \n",
       "PAY_RATIO_6                        0.035492  \n",
       "PAY_RATIO_1_INDICATOR              1.000000  \n",
       "PAY_RATIO_2_INDICATOR              0.000000  \n",
       "PAY_RATIO_3_INDICATOR              0.600000  \n",
       "PAY_RATIO_4_INDICATOR              0.000000  \n",
       "PAY_RATIO_5_INDICATOR              0.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/Sequential_data_trimmed.csv')\n",
    "y = df['Y']\n",
    "\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-khickey/.local/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross-validation results: 0.4631289668146429\n"
     ]
    }
   ],
   "source": [
    "#make pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#split into training and testing\n",
    "Train_data, test_data = train_test_split(df, test_size = 0.2, random_state = 2019)\n",
    "\n",
    "target = 'Y'\n",
    "predictors = [x for x in df.columns if x not in [target] ]\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "oversampler = SMOTE(random_state = 2019)\n",
    "pipeline = Pipeline([('smote', oversampler),('clf', clf)])\n",
    "\n",
    "#cross validate results\n",
    "kfold = KFold(n_splits=5, random_state=2019)\n",
    "results = cross_val_score(pipeline, df[predictors], df[target], cv=kfold, scoring = 'f1')\n",
    "print(f\"5-fold cross-validation results: {np.mean(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross-validation results: 0.4576601559702452\n"
     ]
    }
   ],
   "source": [
    "#testing the cross_val inputs; using only the training data\n",
    "from sklearn.metrics import f1_score\n",
    "clf2 = LogisticRegression()\n",
    "\n",
    "pipeline2 = Pipeline([('smote', oversampler), ('clf', clf2)])\n",
    "\n",
    "results2 = cross_val_score(pipeline2, Train_data[predictors], Train_data[target], cv=kfold, scoring='f1')\n",
    "\n",
    "print(f\"5-fold cross-validation results: {np.mean(results2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross-validation results: 0.4620556630758485\n"
     ]
    }
   ],
   "source": [
    "#testing cross_val on only the testing data\n",
    "clf3 = LogisticRegression()\n",
    "pipeline3 = Pipeline([('smote', oversampler), ('clf', clf3)])\n",
    "\n",
    "results3 = cross_val_score(pipeline3, test_data[predictors], test_data[target], cv=kfold, scoring='f1')\n",
    "\n",
    "print(f\"5-fold cross-validation results: {np.mean(results3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.472495657209033\n"
     ]
    }
   ],
   "source": [
    "#testing the seperate fit to training, and predicting\n",
    "\n",
    "clf4 = LogisticRegression()\n",
    "\n",
    "pipeline4 = Pipeline([('smote', oversampler), ('clf', clf4)])\n",
    "pipeline4.fit(Train_data[predictors], Train_data[target])\n",
    "\n",
    "y_pred = pipeline4.predict(test_data[predictors])\n",
    "\n",
    "print(f\"f1 score: {f1_score(test_data[target], y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-khickey/.local/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/jupyter-khickey/.local/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/jupyter-khickey/.local/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross-validation results: 0.1602779685061767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-khickey/.local/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "results5 = cross_val_score(clf, df[predictors], df[target], cv=kfold, scoring='f1')\n",
    "\n",
    "print(f\"5-fold cross-validation results: {np.mean(results5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross-validation results: 0.45792790390017346\n"
     ]
    }
   ],
   "source": [
    "#make pipeline with randomforest\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#split into training and testing\n",
    "Train_data, test_data = train_test_split(df, test_size = 0.2, random_state = 2019)\n",
    "\n",
    "target = 'Y'\n",
    "predictors = [x for x in Train_data.columns if x not in [target] ]\n",
    "\n",
    "clfRF = RandomForestClassifier()\n",
    "\n",
    "oversampler = SMOTE(random_state = 2019)\n",
    "pipeline = Pipeline([('smote', oversampler),('clf', clfRF)])\n",
    "\n",
    "#cross validate results\n",
    "kfold = KFold(n_splits=5, random_state=2019)\n",
    "results = cross_val_score(pipeline, Train_data[predictors], Train_data[target], cv=kfold, scoring = 'f1')\n",
    "print(f\"5-fold cross-validation results: {np.mean(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross-validation results: 0.3662705580881832\n"
     ]
    }
   ],
   "source": [
    "#compare the xgboost models\n",
    "\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "pipeline5 =  Pipeline([('smote', oversampler),('clf', model)])\n",
    "kfold = KFold(n_splits=5, random_state=2019)\n",
    "results = cross_val_score(pipeline5, Train_data[predictors], Train_data[target], cv=kfold, scoring = 'f1')\n",
    "print(f\"5-fold cross-validation results: {np.mean(results)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
